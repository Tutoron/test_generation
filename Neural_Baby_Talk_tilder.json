{
	"doc_name": "Neural_Baby_Talk",
	"symbol_expr": "\\tilde{r}",
	"sentences": [{
		"type": "text",
		"expr": " It is drawn from the language model , which is associated with a \u201cdefault\u201d sentinel \u201cregion\u201d  $\\tilde{r}$  obtained from the language model\u00a0  (discussed in Sec",
		"word_idx": 14262,
		"sentence_idx": 158,
		"label": "definition"
	}, {
		"type": "math",
		"expr": "$$\\tilde{r}$$",
		"word_idx": 14714,
		"sentence_idx": 168,
		"label": "none"
	}, {
		"type": "text",
		"expr": "Since textual words  $y_{t}^{txt}$  are not tied to specific regions in the image, inspired by\u00a0 , we add a \u201cvisual sentinel\u201d  $\\tilde{r}$  as a latent variable to serve as dummy grounding for the textual word",
		"word_idx": 18231,
		"sentence_idx": 224,
		"label": "definition"
	}, {
		"type": "math",
		"expr": "$$\\tilde{r}$$",
		"word_idx": 18624,
		"sentence_idx": 228,
		"label": "none"
	}, {
		"type": "text",
		"expr": "$p(y_{t}^{txt}|\\bm{y}_{1:t-1})=p(y_{t}^{txt}|\\tilde{r},\\bm{y}_{1:t-1})p(\\tilde{%\nr}|\\bm{y}_{1:t-1})$",
		"word_idx": 18644,
		"sentence_idx": 230,
		"label": "none"
	}, {
		"type": "math",
		"expr": "$$p(y_{t}^{txt}|\\bm{y}_{1:t-1})=p(y_{t}^{txt}|\\tilde{r},\\bm{y}_{1:t-1})p(\\tilde{%\nr}|\\bm{y}_{1:t-1})$$",
		"word_idx": 18744,
		"sentence_idx": 231,
		"label": "none"
	}, {
		"type": "text",
		"expr": "  $\\bm{P}_{\\bm{r}}^{t}$  is the probability distribution over grounding regions  $\\bm{r}_{\\bm{I}}$  and visual sentinel  $\\tilde{r}$ ",
		"word_idx": 20545,
		"sentence_idx": 267,
		"label": "definition"
	}, {
		"type": "text",
		"expr": "\u00a0 9  captures  $p(\\tilde{r}|\\bm{y}_{1:t-1})$ ",
		"word_idx": 20715,
		"sentence_idx": 269,
		"label": "usecase"
	}, {
		"type": "math",
		"expr": "$$\\tilde{r}$$",
		"word_idx": 20884,
		"sentence_idx": 276,
		"label": "none"
	}, {
		"type": "math",
		"expr": "$$p(\\tilde{r}|\\bm{y}_{1:t-1})$$",
		"word_idx": 20893,
		"sentence_idx": 277,
		"label": "usecase"
	}, {
		"type": "text",
		"expr": "\u00a0 10  and  $p(\\tilde{r}|\\bm{y}_{1:t-1})$  from the last element of the vector in Eq",
		"word_idx": 21401,
		"sentence_idx": 285,
		"label": "usecase"
	}, {
		"type": "math",
		"expr": "$$p(\\tilde{r}|\\bm{y}_{1:t-1})$$",
		"word_idx": 21605,
		"sentence_idx": 289,
		"label": "use'"
	}, {
		"type": "text",
		"expr": "$\\displaystyle=-\\sum_{t=1}^{T}\\log\\Big{(}\\overbrace{p(y_{t}^{*}|\\tilde{r},\\bm{y%\n}_{1:t-1}^{*})p(\\tilde{r}|\\bm{y}_{1:t-1}^{*})\\mathbbm{1}_{(y_{t}^{*}=y^{%\n\\textrm{txt}})}}^{\\begin{subarray}{c}\\text{Textual word probability}%\n\\end{subarray}}+$",
		"word_idx": 24303,
		"sentence_idx": 323,
		"label": "none"
	}, {
		"type": "math",
		"expr": "$$\\displaystyle=-\\sum_{t=1}^{T}\\log\\Big{(}\\overbrace{p(y_{t}^{*}|\\tilde{r},\\bm{y%\n}_{1:t-1}^{*})p(\\tilde{r}|\\bm{y}_{1:t-1}^{*})\\mathbbm{1}_{(y_{t}^{*}=y^{%\n\\textrm{txt}})}}^{\\begin{subarray}{c}\\text{Textual word probability}%\n\\end{subarray}}+$$",
		"word_idx": 24545,
		"sentence_idx": 324,
		"label": "none"
	}]
}